{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implementing a Perceptron from scratch"
      ],
      "metadata": {
        "id": "WhS727cziV3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "D4n5GNZLkYKH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a perceptron object\n",
        "\n",
        "Member functions(methods)\n",
        "*   init - initializes weight and bias\n",
        "*   sigmoid - sigmoid function logic\n",
        "*   predict - summation funcation. i.e multiply the input features with weights and add with bias\n",
        "*   fit - update of weight and bais (using stocastic gradient descent)\n",
        "*   evaluate - evaluating the model results\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lrdWoI3WiaLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Rfikav5ET7Pm"
      },
      "outputs": [],
      "source": [
        "class SigmoidPerceptron:\n",
        "  def __init__(self, input_size):\n",
        "    # input_size = numbers of columns in the dataset\n",
        "    self.weights = np.random.randn(input_size) # create a random weight array according to input size\n",
        "    self.bias = np.random.randn(1)\n",
        "\n",
        "  # returns the sigmoid value according to the formula 1/(1+e^-z)\n",
        "  def sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  # calculates the weighted sum: (w1x1 + w2x2 .... +wnxn) + b [w1x1 + w2x2 .... can be calulated by using dot product]\n",
        "  def predict(self, inputs):\n",
        "    z = np.dot(inputs, self.weights) + self.bias\n",
        "    return self.sigmoid(z)\n",
        "\n",
        "  # Update the weights and bais (using stochastic gradient descent)\n",
        "  def fit(self, inputs, targets, learning_rate=0.02, epochs=1):\n",
        "    num_inputs = inputs.shape[0]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      for i in range(len(inputs)):\n",
        "        input_vector = inputs[i]\n",
        "        target_value = targets[i]\n",
        "\n",
        "        prediction = self.predict(input_vector)\n",
        "        error = target_value - prediction\n",
        "\n",
        "        # updating the weight\n",
        "        gradient_weight = error * prediction * (1 - prediction) * input_vector     # calculating gradient of the loss = (\\frac{\\partial L}{\\partial w}\\)\n",
        "        self.weights -= learning_rate * gradient_weight  # wnew = wold - learning rate * gradient of loss\n",
        "\n",
        "        # updating the bias\n",
        "        gradient_bias = error * prediction * (1 - prediction)      # calculating gradient of error wrt bias = (\\frac{\\partial E}{\\partial b}\\)\n",
        "        self.bias -= learning_rate * gradient_bias  # bnew = bold - learning rate * gradient of error wrt bias\n",
        "\n",
        "\n",
        "  def evaluate(self, inputs, targets):\n",
        "    num_inputs = inputs.shape[0]\n",
        "    correct_prediction = 0\n",
        "\n",
        "    for i in range(num_inputs):\n",
        "      input_vector = inputs[i]\n",
        "      target_value = targets[i]\n",
        "\n",
        "      prediction = self.predict(input_vector)\n",
        "\n",
        "      if prediction >= 0.5:\n",
        "        predicted_class = 1\n",
        "      else:\n",
        "        predicted_class = 0\n",
        "\n",
        "      if predicted_class==target_value:\n",
        "        correct_prediction += 1\n",
        "\n",
        "    accuracy = correct_prediction / num_inputs  # accuracy = num of correct predictions / total num of predictions or inputs\n",
        "    return accuracy\n"
      ]
    }
  ]
}